למידת מכונה (באנגלית: Machine Learning; לעיתים מכונה גם למידה חישובית) היא תת-תחום במדעי המחשב ובבינה מלאכותית המשיק לתחומי הסטטיסטיקה והאופטימיזציה. התחום עוסק בפיתוח אלגוריתמים המיועדים לאפשר למחשב ללמוד מתוך דוגמאות, ופועל במגוון משימות חישוביות בהן התכנות הקלאסי אינו אפשרי. אין לבלבל בין תחום זה, שבו המחשב הוא הלומד, ובין למידה ממוחשבת, שבה המחשב משמש כעזר למידה על ידי הרצת לומדה או בדרך אחרת.
שני תחומים מקבילים ללמידת מכונה הם תחום כריית מידע (Data Mining) ותחום זיהוי תבניות (Pattern Recognition) שרבים מן הכלים והאלגוריתמים שפותחו בו משותפים לתחומים הללו.


== הגדרה ==
ארתור סמואל הגדיר את למידת המכונה בשנת 1959 כ-"תחום מחקר המאפשר למחשבים את היכולת ללמוד מבלי להיות מתוכנתים באופן ספציפי".
טום מ. מיטשל סיפק הגדרה פורמלית יותר: "תוכנית מחשב תיקרא לומדת מניסיון E ביחס למחלקת משימות T ומדד ביצועים P, אם הביצועים של משימות ב-T, בהתאם למדד P, משתפרים עם הניסיון E".


== מטרות ושימושים ==
המטרה המרכזית של למידת המכונה היא טיפול ממוחשב בנתונים מן העולם האמיתי עבור בעיה מסוימת, כאשר לא ניתן לכתוב תוכנת מחשב עבורה למשל, בעיית זיהוי שמומחה אנושי מסוגל לפתור, אך לא מסוגל לכתוב את הכללים לזיהוי בצורה מפורשת, או שהם משתנים עם הזמן ולא ניתנים לכתיבה מראש.
מטרת הלמידה יכולה להיות מידול, חיזוי או גילוי (דטקציה) של עובדות לגבי העולם האמיתי. לדוגמה: עבור זיהוי תווים אופטי ניתן להשתמש בלמידת מכונה כדי לגלות מהי האות הכתובה או המודפסת. מערכות זיהוי דיבור יכולות גם הן להשתמש בלמידת מכונה כדי ללמוד, בהינתן אותות קוליים כלשהם, מהי ההברה שיצרה אותם. דוגמה נוספת היא מערכות המלצה, מערכות המבוססות על נתונים המצביעים על קשר בין קבוצת משתמשים/אנשים אקראית לבין קבוצת פריטים שונים, ויודעת למשל להציע פריטים משלימים ללקוחות, בהתבסס על ניתוח נתונים שנלמדו מהעבר מקבוצת אנשים אחרת, שחיפשה פריטים בעלי מאפיינים דומים.


== תאוריה ==
מספר גישות התפתחו עם השנים בתחום התאורטי של למידת מכונה. ההבדלים ביניהן מבוססים על ההנחות השונות לגבי עקרונות ההיסק המשמשים להכללה מתוך מידע מוגבל. הבדלים אילו מבוססים על הגדרות שונות להסתברות (גישה בייסיאנית לעומת גישה קלאסית) והנחות על הדרך בה נוצר המידע (דיסקרמינטיבי לעומת גנרטיבי).
הגישות השונות כוללות את:

למידת PAC (”למידת קרוב לוודאי בערך נכון”; Probably approximately correct) - תאוריה שפותחה על ידי לסלי וליאנט
תאוריית VC - תאוריה שפותחה על ידי ולדימיר ופניק (Vapnik–Chervonenkis theory learning).
הסקה בייסיאנית
תאוריית למידה אלגוריתמית - מתוך עבודתו של א.מ גולד (Algorithmic learning theory ).בעקבות הגישות התאורטיות צמחו מספר אלגוריתמים מעשיים. למשל, תאוריית PAC עוררה השראה לאלגורתמי Boosting, תאוריית VC הובילה לאלגוריתם מכונת וקטורים תומכים (SVM) והסקה בייסיאנית הובילה לאלגוריתמי רשתות בייסיאניות.

הכללה (Generalization)
המטרה הבסיסית של מכונה לומדת היא היכולת להכליל מתוך הניסיון. כלומר היכולת לבצע (חיזוי, סיווג, רגרסיה וכו') באופן מדויק ככל האפשר על מידע (דוגמאות\משימות) שעדיין לא נצפה, על בסיס צבירת ניסיון ממידע קיים. בדרך כלל דוגמאות המשמשות ללימוד נוצרות מאיזושהי התפלגות לא ידועה והמכונה הלומדת בונה מודל מוכלל מאותו מרחב של ההתפלגות, מה שמאפשר ביצוע מדויק באופן מספק על דוגמאות חדשות.הסקה והחלטה
בבעיית סיווג יש לנו K מחלקות (או קטגוריות) 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
   ולכל פריט (או תצפית) x עלינו להחליט לאיזה מחלקה הוא שייך. כאשר אנו מדברים על בעיית סיווג בדרך כלל נחלק את הבעיה לשני שלבים. בשלב הראשון נרצה להסיק (inference) מתוך סט האימון את ההתפלגות האחודה 
  
    
      
        p
        (
        x
        ,
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle p(x,C_{k})}
  , שמספקת לנו תיאור הסתברותי שלם על המצב. בשלב שני נרצה להחליט (Decision) במידה אופטימלית על מידע חדש שלא ראינו בסט האימון לאילו מן המחלקות 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
   הוא שייך וזאת על סמך ההתפלגות שמצאנו בשלב הראשון. לעיתים שלב ההחלטה יכול להיות טריוויאלי ולהיגזר ישירות מהשלב הראשון.ניתן לזהות שלוש גישות שונות לפתרון בעיות החלטה:

תחילה נפתור את בעיית ההסקה על ידי קביעת ההסתברויות המותנות 
  
    
      
        p
        (
        x
        
          |
        
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle p(x|C_{k})}
   באופן נפרד לכל מחלקה 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
  , הסתברות זו מכונה לעיתים "הנראות" (Likelihood) של המחלקה 
  
    
      
        
          C
          
            k
          
        
      
    
    {\displaystyle C_{k}}
  . בנפרד נקבע את ההסתברות "הא-פריורית" (Prior) של המחלקות השונות 
  
    
      
        p
        (
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle p(C_{k})}
   שאותה אנו יודעים לעיתים מתוך האוכלוסייה הכללית. ואז נמצא את ההסתברות "הפוסטריורית" (Posterior) 
  
    
      
        p
        (
        
          C
          
            k
          
        
        
          |
        
        x
        )
      
    
    {\displaystyle p(C_{k}|x)}
   באמצעות משפט בייס שהוא מן הצורה:
  
    
      
        p
        (
        
          C
          
            k
          
        
        
          |
        
        x
        )
        =
        
          
            
              p
              (
              x
              
                |
              
              
                C
                
                  k
                
              
              )
              p
              (
              
                C
                
                  k
                
              
              )
            
            
              p
              (
              x
              )
            
          
        
      
    
    {\displaystyle p(C_{k}|x)={\frac {p(x|C_{k})p(C_{k})}{p(x)}}}
   את ההסתברות 
  
    
      
        p
        (
        x
        )
      
    
    {\displaystyle p(x)}
   ניתן לחשב מתוך כלל הסכום בצורה הבאה: 
  
    
      
        p
        (
        x
        )
        =
        
          ∑
          
            k
          
        
        p
        (
        x
        
          |
        
        
          C
          
            k
          
        
        )
        p
        (
        
          C
          
            k
          
        
        )
      
    
    {\displaystyle p(x)=\sum _{k}p(x|C_{k})p(C_{k})}
    בהינתן ההסתברויות הפוסטריוריות נפעיל את כלל ההחלטה לקבוע לאיזו מחלקה שייכת דוגמה חדשה. גישות מסוג זה מכונות גם מודלים גנרטיביים (Generative Models), משום שלאחר קביעת ההתפלגויות ניתן לייצר מהן דוגמאות סינתטיות.
תחילה נפתור את בעיית ההסקה על ידי קביעת ההסתברות הפוסטריורית 
  
    
      
        p
        (
        
          C
          
            k
          
        
        
          |
        
        x
        )
      
    
    {\displaystyle p(C_{k}|x)}
   ואז נפעיל את כלל ההחלטה לקבוע לאיזו מחלקה שייכת דוגמה חדשה. גישות מסוג זה מכונות גם מודלים דיסקרימינטיביים (Discriminative Models).
נמצא פונקציה 
  
    
      
        f
        (
        x
        )
      
    
    {\displaystyle f(x)}
   הנקראת פונקציה דיסקרמיננטית, הממפה כל x למחלקה מסוימת. במקרה זה אין שימוש בהסתברות.


== סוגי למידה ==
נהוג לחלק את אלגוריתמי למידת המכונה למספר סוגים:

למידה מונחית (supervised learning). כל דוגמה מגיעה עם תווית סיווג. מטרת האלגוריתם היא לחזות את הסיווג של דוגמאות חדשות שאותן לא פגש בתהליך הלמידה. אימון של רשת עצבית מלאכותית ("רשת נוירונים") מסתמך על אלגוריתמים מסוג זה.
למידה בלתי מונחית (unsupervised learning). מטרת האלגוריתמים היא למצוא ייצוג פשוט וקל להבנה של אוסף הנתונים. שיטות נפוצות מסוג זה הן חלוקה לצברים (clustering), והטלה ליריעות ממד נמוך כגון ניתוח גורמים ראשיים (PCA).
למידת חיזוק (reinforcement learning). אלגוריתם הלמידה מקבל משוב חלקי על ביצועיו (רק לאחר סיום ביצוע המטלה) ועליו להסיק אילו מהחלטותיו הביאו להצלחה/כישלון.


== סוגי בעיות ==
ניתוח אשכולות - חלוקת הדוגמאות הנתונות למספר קבוצות, ושיוך דוגמה חדשה לקבוצה המתאימה ביותר.
קטגוריזציה - זיהוי הקטגוריה הנכונה עבור הדוגמה החדשה מתוך סט הקטגוריות הנתונות.
הכרעה בינארית - שיוך הדוגמה החדשה לאחת משתי קטגוריות בלבד.


== אלגוריתמים נפוצים ==

למידת מכונה כוללת אוסף ידוע של כמה עשרות אלגוריתמים. ניתן לסווג אלגוריתמים אילו על פי מספר תבחינים.


==== עצלנים (Lazy) מול חרוצים (Eager) ====
אלגוריתם עצלן לא מבצע חישוב עד שלא מתבקש לענות על שאלה. כאשר נשאלת שאלה האלגוריתם אוסף נתונים רלוונטיים, מבצע חישוב ונותן תשובה. דוגמה לאלגוריתם עצל הוא אלגוריתם שכן קרוב.
למולם האלגוריתמים החרוצים משתמשים בנתוני הלימוד על מנת לבנות מודל מתמטי אשר מהווה בסיס לפתרון הבעיה. כאשר האלגוריתם מתבקש לענות על שאלה הוא משתמש בנתוני השאלה על מנת לפתור את המודל. דוגמה לאלגוריתם חרוץ הוא  אלגוריתם של אשכולות (Clusterization).


==== מקומי (Local) מול גלובלי (Global) ====
אלגוריתם מקומי הוא אלגוריתם שמחשב פתרון שתקף רק לסביבה שבה נשאלה השאלה. דוגמה לכך היא רגרסיה מקומית עם משקלות. אלגוריתם זה מחשב קו (או משטח) רגרסיה בהתאם לנקודות בסביבה נתונה. כל נקודה בתהליך הרגרסיה מקבלת משקל הפוך למרחקה מהמקום שבו מחושב המודל.
אלגוריתם גלובלי לעומתו מחשב מודל שאמור להיות תקף בכל מרחב הנתונים הרלוונטי.
להלן מספר אלגוריתמים ידועים:

אלגוריתם שכן קרוב - ("K-nearest neighbors")
עץ החלטה לומד
ID3 - עץ החלטה עם משתנים קטגוריאליים בלבד.
C4.5 - עץ החלטה עם משתנים רציפים.
רגרסיה מקומית
רשת עצבית מלאכותית
רשתות ביסיאניות 
אשכולות מבוססי מרחק - (KMean Clustering)
אלגוריתם ציפייה - מקסום - (Expectation–maximization)
אלגוריתם גנטי
אלגוריתמים של לימוד מתקן:
BOOSTING
BAGGING
חוקים אסוציאטיבים
PSO - אופטימיזציה מבוססת תבונת נחיל.
ACO - אופטימיזציה מבוססת תבונת נמלים.
רשת קוהונן - לימוד של פונקציית צפיפות לא פרמטרית.
Parallel Coordinates - קואורדינטות מקבילות
מכונת וקטורים תומכים (SVM) - אלגוריתם דיסקרמיננטי המשמש למציאת ווקטורים המפרידים בצורה אופטימלית בין מחלקות המידע.


== היסטוריה ==
התפתחות למידת המכונה הוא חלק אינטגרלי מהתפתחות תחום הבינה המלאכותית. בתחילת הדרך עיקר המאמץ היה לחקות את התנהגות המוח האנושי. מודל הפרספטרון הומצא בשנת 1957 ויצר תקווה רבה בתחום בשנות ה-60. מגבלותיו של המודל לייצג פונקציות מורכבות הועלו על ידי מארוין מינסקי, דבר שהשפיע על חוקרים רבים באותה תקופה לעצור מלפתח את המודל במהלך השנים הבאות.
במהלך שנות ה-70 של המאה ה-20 תחום למידת המכונה נכנס לסוג של תרדמת כאשר מערכות מומחה היוו את מוקד העניין בתחום הבינה המלאכותית. באמצע שנות השמונים החלה תקומה חוזרת בתחום כאשר הומצאו עצי ההחלטה והופצו בתוכנה, ויתרונם היה ביכולת להציגם ובקלות הסברתם. בנוסף הם היו מגוונים ונתנו מענה למספר רב של בעיות. גם המודלים של רשתות נוירונים החלו להתפתח מחדש, כשתהליך ההתפשטות לאחור (back-propagation) היווה פריצת דרך בתחום. רשתות הנוירונים עם השכבות הנסתרות יכלו עתה להביע פונקציות רבות ואפשרו להתגבר על מגבלותיו של הפרספטרון. גם עצי ההחלטה וגם רשתות הנוירונים שימשו עתה באפליקציות פיננסיות כגון אישור הלוואות, זיהוי תרמיות וניהול תיקים, ובתעשייה הם שיפרו תהליכים רבים למשל בתחום האוטומציה בדואר.
בשנות התשעים עם כניסת האינטרנט ותחילתו של עידן התפוצצות המידע החלה התקדמות רבה בתחום למידת המכונה. בשנת 1995 פורסם לראשונה אלגוריתם מכונת וקטורים תומכים (SVM), ואומץ כאלגוריתם מוביל. תוכנות קוד פתוח שנכתבו לאלגוריתם הפכו אותו פופולרי לשימוש.
בשנים האחרונות חלו התפתחויות נוספות בתחום, רגרסיה לוגיסטית התגלתה מחדש ועוצבה לתת מענה לבעיות עם טווח רחב יותר. אלגוריתמים כמו "נאיב בייס", רשתות בייסיאניות, ומקסימום אנטרופיה הביאו לתוצאות מצוינות במגוון בעיות. בעקבותיהם פותחו אלגוריתמים משולבים, המשתמשים באנסמבל של מסווגים כגון אלגוריתם אדה בוסט, ויערות אקראיים, שגם הם הביאו לשיפור ניכר בתוצאות.
תת תחום נוסף שהפך פופולרי מהעשור הראשון של המאה ה-21 הוא תחום הלמידה העמוקה (Deep Learning),שמתבסס על רשתות נוירונים בעלות מספר רב של שכבות. השימוש הפופולרי במושג "deep belief nets" ובקיצור רשתות עמוקות נטבע במאמר המשפיע מ-2006 של הינטון, אוסינדרו וטה.


=== מגמות מתפתחות ===
מגמה המתפתחת בתחום למידת המכונה, היא הסביבה בה פועלות מכונות אלו. כאשר המונח "סביבה" מתייחס לארכיטקטורת המחשוב בה מתבצעת למידת המכונה. בעוד, בעבר למידת מכונה קלאסית, יוחסה לתוכנית בודדת הרצה בסביבת מחשב בודד, הרי שכיום, הארכיטקטורה מתרחבת לכדי רשתות מחשבים לומדות, תוך שימוש בעשרות אלפי מחשבים וניצול כוחם של עשרות אלפי מעבדים המשובצים בהם.
המונח "סביבה" מתייחס לא רק לארכיטקטורה, אלא גם למקורות איסוף הנתונים, שנע החל מקבוצת אנשים אקראית, דרך מנתח נתונים (דאטא-אנליסט), מקבל החלטה לו יש סוג מסוים של (סט) דרישות ממערכת לומדת זאת ועד למסגרת חברתית, פוליטית, חוקית, הסובבת סביב פריסת המערכת. מערכת לומדת, יכולה לכלול בסביבה שלה גם תתי מערכות לומדות המתקשרות עמה באמצעות רשת תקשורת ותוכנה ייעודית.


== לקריאה נוספת ==
שי בן-דוד, שי שלו-שוורץ, Understanding Machine Learning: From Theory to Algorithms, אוניברסיטת קמברידג', ISBN 9781107057135. (באנגלית)


== קישורים חיצוניים ==

רשימת חוקרים בתחום ה-Machine learning בישראל
Alex Wissner-Gross: A new equation for intelligence – הרצאה מאתר TED על הגדרת האינטליגנציה כשאיפה למיקסום אפשרויות עתידיות 
יובל דרור, החיפוש אחר ה"מאסטר אלגוריתם" המושלם, באתר הארץ, 19 בינואר 2016
למידת מכונה ובינה מלאכותית - הרצאה של ויויאן מינגדוגמאות ללמידת מכונה בישראל:

The HUJI Machine Learning Lab
קורס למידה חישובית (למידת מכונה) - פרופ' ליאור רוקח 
Machine Learning Israel
למידת מכונה, באתר אנציקלופדיה בריטניקה (באנגלית)


== הערות שוליים ==