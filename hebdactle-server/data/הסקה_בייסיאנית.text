הסקה בייסיאנית (אנגלית: Bayesian inference, על שמו של תומאס בייס) היא שיטת הסקה סטטיסטית המבוססת על נוסחת בייס. הנוסחה משמשת לעדכון ההסתברות לקיום הנחה על ידי הוספת מידע נוסף. שיטה זו חשובה בסטטיסטיקה, במיוחד במקרים של מידע המתעדכן באופן דינמי. שיטה זו מצאה שימוש נרחב במדע, הנדסה, רפואה ודין. שיטה זו מוצגת לפעמים כשיטה מתחרה להסקה שכיחותנית.


== חוק בייס ==
 ערך מורחב – חוק בייסנוסחת בייס מסיקה הסתברות פוסטריורית בהינתן הסתברות פריורית ופונקציית נראות שנתונים על ידי המודל הסטטיסטי. ההסתברות נתונה על ידי הנוסחה:

  
    
      
        P
        (
        H
        ∣
        E
        )
        =
        
          
            
              P
              (
              E
              ∣
              H
              )
              ⋅
              P
              (
              H
              )
            
            
              P
              (
              E
              )
            
          
        
      
    
    {\displaystyle P(H\mid E)={\frac {P(E\mid H)\cdot P(H)}{P(E)}}}
  כאשר: 

H היא השערה, עם הסתברות שיכולה להתעדכן בהתאם למידע חדש. במקרים מסוימים ישנן מספר השערות מתחרות ומטרת השיטה היא לבחור את הסבירה ביותר.
E היא ראיה, המספקת מידע חדש שלא היה קיים בחישוב הסתברות פריורית.

  
    
      
        
          P
          (
          H
          )
        
      
    
    {\displaystyle \textstyle P(H)}
   זו ההסתברות פריורית של H, כלומר הערכת ההסתברות של H ללא ראיה E.

  
    
      
        
          P
          (
          H
          ∣
          E
          )
        
      
    
    {\displaystyle \textstyle P(H\mid E)}
   היא הסתברות אפוסטריורית, כלומר ההסתברות ל-H בהינתן E. במילים אחרות, לאחר קבלת המידע E, מהי הסבירות לכך ש-H אכן התרחש. זהו המידע שאותו רוצים להסיק.

  
    
      
        
          P
          (
          E
          )
        
      
    
    {\displaystyle \textstyle P(E)}
   היא ההסתברות להתרחשות E, נקראת לפעמים נראות שולית. ערך זה הוא זהה לכל ההשערות הנבדקות וניתן על ידי נוסחת ההסתברות השלמה: 
  
    
      
        P
        (
        E
        )
        =
        ∑
        P
        (
        E
        
          |
        
        
          H
          
            i
          
        
        )
        P
        (
        
          H
          
            i
          
        
        )
      
    
    {\displaystyle P(E)=\sum P(E|H_{i})P(H_{i})}
  , כלומר ההסתברות להתרחשות E בכל התרחישים האפשריים.


== הסבר אינטואיטיבי ==
במקרה והראיה סותרת את ההשערה, אז ההשערה שגויה. ומצד שני, אם ההשערה לא סבירה אפריורי (כלומר ללא מידע על הראיה), אז ניתן לפסול השערה זו גם אם כעיקרון הראיה תומכת בה. 
לדוגמה, אדם מנסה לנחש את מין הילוד על סמך צבעה של העריסה העומדת מול דלת חדרו. הצבע יכול לתמוך בהשערה זו או אחרת של הצופה. אך המצאות של מלונה במקום עריסת תינוק משאירה את ההסתברות הפוסטריאורית לכך שהילוד הוא כלב נמוכה מאוד. למרות הראיה (הימצאות מלונה), ההסתברות האפוסטריורית לכך שלמשפחה נולד כלב נשארת נמוכה מאוד, מכיוון שידוע שההסתברות האפריורית ללידת כלב על ידי אדם היא נמוכה מאוד.
כך, הנקודה החשובה בהסקה בייסיאנית שהיא מאפשרת להחשיב ראיות חדשות, תוך כדי הסתמכות על אמונות וידע קודם, תוך שימוש בחוק בייס. זאת לעומת הסקה שכיחותנית, המסיקה מסקנות על סמך ראיות, ללא שימוש בידע קודם.
נוסף על כך, חוק בייס יכול לשמש באופן איטרטיבי. כלומר, לאחר קבלת ראיה, ההסתברות האפוסטריורית יכולה לשמש כהסתברות אפריורית לחקירת הראיה הבאה. ולאחר קבלת ראיה חדשה ההסתברות האפוסטריורית תשמש לאיטרציה הבאה. שיטה זו נקראת לפעמים "עדכון בייסיאני" (Bayesian updating).


== ראו גם ==
הסתברות בייסיאנית
בעיית הטנק הגרמני